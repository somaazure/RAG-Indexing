```markdown
# ðŸ§  RAGify: A Minimal Retrieval-Augmented Generation (RAG) System with LangChain & OpenAI

A clean, modular RAG (Retrieval-Augmented Generation) pipeline built using LangChain, ChromaDB, and OpenAI's GPT â€” ideal for LLM-powered search, Q&A over private documents, and real-world GenAI prototypes.

---

## ðŸš€ Project Vision

Modern LLMs like ChatGPT struggle with up-to-date or domain-specific knowledge. This project solves that using **RAG (Retrieval-Augmented Generation)** â€” where we:

1. **Index local documents** (PDFs, `.txt`, etc.) as vector embeddings
2. **Query over them** using natural language
3. **Generate accurate answers** using OpenAI's `gpt-3.5-turbo`

ðŸ“Œ **Use Cases**:
- Chat with local files or docs
- Enterprise knowledge base search
- Legal/finance/healthcare domain-specific assistants
- LLM-backed intranet or internal wikis

---

## ðŸ› ï¸ Tech Stack

| Layer               | Tool                          |
|--------------------|-------------------------------|
| LLM                 | OpenAI GPT (`gpt-3.5-turbo`) |
| Embeddings          | OpenAI Embeddings API        |
| Vector Store        | ChromaDB (local)             |
| Index Deduplication | LangChain `SQLRecordManager` |
| Query Interface     | CLI (extensible to web)      |
| Language            | Python 3.9+                  |

---

## ðŸ§± Features

- âœ… Local RAG setup â€” no cloud dependencies beyond OpenAI
- âœ… Efficient document indexing with deduplication
- âœ… One-line natural language Q&A
- âœ… Modular code: `Indexer`, `Query`, LLM interface
- âœ… SQLite-backed document change tracking
- âœ… Minimal and fast â€” perfect for learning or extension

---

## ðŸ“ Folder Structure

```

ragify/
â”œâ”€â”€ app.py              # Indexing script (creates vector store)
â”œâ”€â”€ query\_rag.py        # CLI for asking questions
â”œâ”€â”€ sample.txt          # Sample knowledge base file
â”œâ”€â”€ .env                # Store your OpenAI API key
â”œâ”€â”€ README.md           # This file
â”œâ”€â”€ chroma\_store/       # Vector DB (auto-generated)
â”œâ”€â”€ index\_log.db        # SQLite log for deduplication

````

---

## âš™ï¸ Setup Instructions

### 1ï¸âƒ£ Clone the repo
```bash
git clone https://github.com/your-username/ragify.git
cd ragify
````

### 2ï¸âƒ£ Install dependencies

```bash
pip install -r requirements.txt
```

> Youâ€™ll need: `langchain`, `openai`, `chromadb`, `python-dotenv`

### 3ï¸âƒ£ Add your OpenAI API key

Create a `.env` file:

```env
OPENAI_API_KEY=sk-xxxxxxxxxxxxxxxx
```

### 4ï¸âƒ£ Index your knowledge file

Replace `sample.txt` with your own `.txt` or document:

```bash
python app.py
```

### 5ï¸âƒ£ Ask Questions!

```bash
python query_rag.py
```

---

## ðŸ’¡ Example

> **User Input**:
> What is the capital city of India?

> **AI Response**:
> The capital city of India is New Delhi.

---

## ðŸ§ª Test It Yourself

Try changing `sample.txt` to contain different information and re-run `app.py`. The system uses file hashes to avoid redundant re-indexing and assigns unique UUIDs to each chunk.

---

## ðŸŒ± Roadmap

* [ ] Add PDF & DOCX support
* [ ] Add Streamlit/Gradio UI
* [ ] Add chunk filtering by metadata
* [ ] Add FAISS / PGVector as plug-and-play alternatives

This project demonstrates:

* ðŸ” Understanding of vector databases & embeddings
* ðŸ¤– Practical application of OpenAI GPT with local data
* ðŸ§± Modular Python architecture
* ðŸ§  End-to-end GenAI knowledge (RAG, dedup, prompt chaining)
* âš™ï¸ Tools like LangChain, ChromaDB, dotenv, and more

> âœ¨ I'm excited to apply these concepts in production-level AI/ML workflows. Letâ€™s build something smarter together!

## ðŸ“œ License

MIT License â€” free to use and extend!


